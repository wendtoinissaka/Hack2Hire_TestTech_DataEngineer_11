
# ðŸŒ¤ï¸ Weather Data Pipeline avec Apache Airflow ðŸš€


## ðŸ“ Description du Projet


Ce projet est une solution d'automatisation de pipeline de donnÃ©es mÃ©tÃ©orologiques utilisant Apache Airflow pour orchestrer et automatiser la rÃ©cupÃ©ration, la transformation (selection des caractÃ©ristiques souhaiter) et le chargement (ETL) des donnÃ©es mÃ©tÃ©o des villes de Dakatr et de Saint-Louis. Les donnÃ©es sont rÃ©cupÃ©rÃ©es via l'API [OpenWeatherMap](https://openweathermap.org/) ðŸŒ. La version gratuite de l'API permet de d'avoir les donnÃ©es de la [mÃ©tÃ©o courante](https://openweathermap.org/current#one) et d'avoir des previsions mÃ©tÃ©o pour les [5 prochains jours](https://openweathermap.org/forecast5#data). Les donnÃ©es obtenus a la fin du processus sont stockÃ©es dans une base de donnÃ©es PostgreSQL gratuite et dsponible sur [Render.com](https://render.com/).

L'objectif final est de crÃ©er des dashboards interactifs avec Power BI ðŸ“Š pour suivre et analyser l'Ã©volution de la tempÃ©rature et d'autres indicateurs mÃ©tÃ©orologiques.


---


## ðŸš€ FonctionnalitÃ©s Principales

ðŸ”„ RÃ©cupÃ©ration AutomatisÃ©e des DonnÃ©es : Utilisation de DAGS (Directed Acyclic Graphs) pour orchestrer l'extraction de donnÃ©es mÃ©tÃ©orologiques en temps rÃ©el ou en diffÃ©rÃ©.

ðŸ§¹ Transformation des DonnÃ©es : Filtrage et extraction des informations clÃ©s (nom de la ville, tempÃ©rature, description mÃ©tÃ©o, pression, humiditÃ©, timestamp).

ðŸ“¤ Chargement dans PostgreSQL : Insertion des donnÃ©es transformÃ©es dans une base de donnÃ©es PostgreSQL distante.

ðŸ“Š Visualisation avec Power BI : CrÃ©ation de tableaux de bord pour suivre et analyser les donnÃ©es mÃ©tÃ©orologiques.

ðŸ—‚ï¸ Gestion des Fichiers IntermÃ©diaires : Les donnÃ©es brutes et transformÃ©es sont enregistrÃ©es sous format JSON entre les diffÃ©rentes Ã©tapes du pipeline.


---


## âš™ï¸ Technologies UtilisÃ©es

ðŸŒ€ Orchestration : Apache Airflow

ðŸŒ API MÃ©tÃ©o : OpenWeatherMap (version gratuite)

ðŸ—„ï¸ Base de DonnÃ©es : PostgreSQL (instance gratuite sur Render.com)

ðŸ“Š Visualisation : Power BI

ðŸ—‚ï¸ Stockage IntermÃ©diaire : JSON

ðŸ³ Conteneurisation : Docker


---


## ðŸ—ï¸ Architecture du Pipeline

Notre systÃ¨me est representÃ© par le schÃ©ma suivant 

![image](https://github.com/user-attachments/assets/5d37537f-d726-4275-97cb-2242c04db985)






---



## ðŸ”„ DÃ©roulement du Pipeline ETL


1. ðŸŒ RÃ©cupÃ©ration des DonnÃ©es (Phase 1)

Un DAG Airflow exÃ©cute des requÃªtes vers l'API OpenWeatherMap pour rÃ©cupÃ©rer les donnÃ©es mÃ©tÃ©orologiques.

Les donnÃ©es brutes sont enregistrÃ©es au format JSON.

2. ðŸ§ª Transformation des DonnÃ©es (Phase 2)

Un second DAG prend les donnÃ©es JSON et applique des transformations pour extraire uniquement les champs pertinents (nom de la ville, tempÃ©rature, description mÃ©tÃ©o, pression, humiditÃ©, timestamp).

Ces donnÃ©es sont Ã©galement enregistrÃ©es en JSON avant d'Ãªtre chargÃ©es.

3. ðŸ“¤ Chargement dans PostgreSQL (Phase 3)

Les donnÃ©es transformÃ©es sont lues depuis le fichier json puis sont insÃ©rÃ©es dans une base de donnÃ©es PostgreSQL distante.

Airflow permet de gerer la connexion et l'insertion des donnÃ©es de maniÃ¨re automatisÃ©e.

4. ðŸ“Š Visualisation avec Power BI

Les donnÃ©es prÃ©sentes dans PostgreSQL sont exploitÃ©es pour crÃ©er des visualisations et dashboards interactifs.

Ci-dessous les differents dashboards rÃ©alisÃ©s : 



1. PrÃ©vision mÃ©tÃ©o pour la rÃ©gion de Dakar :

![image](https://github.com/user-attachments/assets/cf269fc6-5e1f-4267-9993-2cd08bd62024)


2. PrÃ©vision mÃ©tÃ©o pour la rÃ©gion de ThiÃ¨s :

![image](https://github.com/user-attachments/assets/b62e6469-eace-47d2-a7e4-62fa3de29088)




---


# âœ… PrÃ©-requis


- Python 3.10 ou plus

- ðŸŒ€ Apache Airflow installÃ© et configurÃ©.
 
- ðŸ³ Docker installÃ©.

- AccÃ¨s Ã  l'API OpenWeatherMap (ClÃ© API requise).

- PostgreSQL (hÃ©bergÃ© ou local avec accÃ¨s distant configurÃ©).

- Power BI pour les dashboards.


---


## ðŸ› ï¸ Installation et Configuration


1. ðŸ“¥ Clonez le RÃ©fÃ©rentiel

            git clone https://github.com/wendtoinissaka/Hack2Hire_TestTech_DataEngineer_11.git
            cd  Hack2Hire_TestTech_DataEngineer_11


2. ðŸ³ Lancer avec Docker Compose

Un fichier docker-compose.yml est disponible Ã  la racine du projet. Pour lancer l'application avec Airflow et PostgreSQL :

      docker-compose up -d

Acceder a l'interface

      http://localhost:8080

Les identifiants sont "Airflow" pour le login et "Airflow pour le password.


---


## ðŸ”§ Utilisation

- DÃ©clenchez le DAG pour rÃ©cupÃ©rer les donnÃ©es de l'API.

- Laissez Airflow exÃ©cuter les transformations automatiques.

- Consultez la base de donnÃ©es PostgreSQL pour vÃ©rifier l'ingestion des donnÃ©es.

- Verifier les logs en cas de problemes

- CrÃ©ez des dashboards sur Power BI connectÃ©s Ã  la base PostgreSQL.


---


## ðŸ‘¤ðŸ‘¤ Auteurs


1. **[Wendtoin Issaka OUEDRAOGO](#)**  ------------------>  [CV](cv/cv_issaka.pdf)  

2. **[Mafoya Elie Abissola ADJOBO](#)**  ------------------->  [CV](cv/CV%20Elie%20Adjobo.pdf)


---

## Documentation

Ressource officiel d'[Apache airflow pour l'utilisation avec Docker](https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html)

Video youtube expliquant l'[installation d'airflow avec Docker](https://www.youtube.com/watch?v=Sva8rDtlWi4)

